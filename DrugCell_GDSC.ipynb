{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lambda_stor/homes/ac.tfeng/git/DrugCell'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/ac.tfeng/miniconda3/envs/general/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Union, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "import copy\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codes.utils.util import *\n",
    "from codes.drugcell_NN import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = 'cuda'\n",
    "else:\n",
    "  DEVICE = 'cpu'\n",
    "  \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 23 11:06:02 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:3D:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:3E:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    57W / 300W |    595MiB / 32768MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    40W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    6   N/A  N/A   1586290      C   python                            592MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:7'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_idx = pd.read_csv(\"data/GDSC/GDSCv1_split_0_train.txt\")\n",
    "train_sample_idx = list(train_sample_idx.iloc[:,0])\n",
    "test_sample_idx = pd.read_csv(\"data/GDSC/GDSCv1_split_0_test.txt\")\n",
    "test_sample_idx = list(test_sample_idx.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_names_in_multilevel_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    level_map: dict,\n",
    "    gene_system_identifier: Union[str, List[str]]=\"Gene_Symbol\") -> pd.DataFrame:\n",
    "    \"\"\" Util function that supports loading of the omic data files.\n",
    "    Returns the input dataframe with the multi-level column names renamed as\n",
    "    specified by the gene_system_identifier arg.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): omics dataframe\n",
    "        level_map (dict): encodes the column level and the corresponding identifier systems\n",
    "        gene_system_identifier (str or list of str): gene identifier system to use\n",
    "            options: \"Entrez\", \"Gene_Symbol\", \"Ensembl\", \"all\", or any list\n",
    "                     combination of [\"Entrez\", \"Gene_Symbol\", \"Ensembl\"]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the input dataframe with the specified multi-level column names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    level_names = list(level_map.keys())\n",
    "    level_values = list(level_map.values())\n",
    "    n_levels = len(level_names)\n",
    "    \n",
    "    if isinstance(gene_system_identifier, list) and len(gene_system_identifier) == 1:\n",
    "        gene_system_identifier = gene_system_identifier[0]\n",
    "\n",
    "    # print(gene_system_identifier)\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if isinstance(gene_system_identifier, str):\n",
    "        if gene_system_identifier == \"all\":\n",
    "            df.columns = df.columns.rename(level_names, level=level_values)  # assign multi-level col names\n",
    "        else:\n",
    "            df.columns = df.columns.get_level_values(level_map[gene_system_identifier])  # retian specific column level\n",
    "    else:\n",
    "        assert len(gene_system_identifier) <= n_levels, f\"'gene_system_identifier' can't contain more than {n_levels} items.\"\n",
    "        set_diff = list(set(gene_system_identifier).difference(set(level_names)))\n",
    "        assert len(set_diff) == 0, f\"Passed unknown gene identifiers: {set_diff}\"\n",
    "        kk = {i: level_map[i] for i in level_map if i in gene_system_identifier}\n",
    "        # print(list(kk.keys()))\n",
    "        # print(list(kk.values()))\n",
    "        df.columns = df.columns.rename(list(kk.keys()), level=kk.values())  # assign multi-level col names\n",
    "        drop_levels = list(set(level_map.values()).difference(set(kk.values())))\n",
    "        df = df.droplevel(level=drop_levels, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_gene_expression_data(gene_expression_file_path, \n",
    "    gene_system_identifier: Union[str, List[str]]=\"Gene_Symbol\",\n",
    "    sep: str=\"\\t\",\n",
    "    verbose: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns gene expression data.\n",
    "\n",
    "    Args:\n",
    "        gene_system_identifier (str or list of str): gene identifier system to use\n",
    "            options: \"Entrez\", \"Gene_Symbol\", \"Ensembl\", \"all\", or any list\n",
    "                     combination of [\"Entrez\", \"Gene_Symbol\", \"Ensembl\"]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with the omic data\n",
    "    \"\"\"\n",
    "    # level_map encodes the relationship btw the column and gene identifier system\n",
    "    level_map = {\"Ensembl\": 0, \"Entrez\": 1, \"Gene_Symbol\": 2}\n",
    "    header = [i for i in range(len(level_map))]\n",
    "\n",
    "    df = pd.read_csv(gene_expression_file_path, sep=sep, index_col=0, header=header)\n",
    "\n",
    "    df.index.name = \"improve_sample_id\"  # assign index name\n",
    "    df = set_col_names_in_multilevel_dataframe(df, level_map, gene_system_identifier)\n",
    "    if verbose:\n",
    "        print(f\"Gene expression data: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene expression data: (1007, 30805)\n"
     ]
    }
   ],
   "source": [
    "gene_express = load_gene_expression_data(\"data/GDSC/cancer_gene_expression.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/ac.tfeng/miniconda3/envs/general/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.max(gene_express))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>GCLC</th>\n",
       "      <th>NFYA</th>\n",
       "      <th>...</th>\n",
       "      <th>PANO1</th>\n",
       "      <th>XGY2</th>\n",
       "      <th>FLJ43315</th>\n",
       "      <th>LOC105377369</th>\n",
       "      <th>PRRC2B</th>\n",
       "      <th>UGT1A3</th>\n",
       "      <th>UGT1A5</th>\n",
       "      <th>F8A2</th>\n",
       "      <th>LOC105377063</th>\n",
       "      <th>F8A1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improve_sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACH-000016</th>\n",
       "      <td>4.189825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.126601</td>\n",
       "      <td>2.114367</td>\n",
       "      <td>2.235727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.094553</td>\n",
       "      <td>5.907131</td>\n",
       "      <td>6.029453</td>\n",
       "      <td>3.669027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.838700</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.356144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000032</th>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.883376</td>\n",
       "      <td>3.549669</td>\n",
       "      <td>5.307064</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>4.758090</td>\n",
       "      <td>5.542568</td>\n",
       "      <td>...</td>\n",
       "      <td>1.189034</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.320124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.493455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000033</th>\n",
       "      <td>4.682573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.949185</td>\n",
       "      <td>1.823749</td>\n",
       "      <td>3.837943</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>6.224002</td>\n",
       "      <td>4.825786</td>\n",
       "      <td>4.408032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963474</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.367371</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.638364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>3.270529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000043</th>\n",
       "      <td>3.499527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.612647</td>\n",
       "      <td>1.952334</td>\n",
       "      <td>2.726831</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.630813</td>\n",
       "      <td>6.098664</td>\n",
       "      <td>5.210623</td>\n",
       "      <td>3.148934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895303</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.616475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.726831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000049</th>\n",
       "      <td>4.262283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.536985</td>\n",
       "      <td>2.087463</td>\n",
       "      <td>4.051372</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>6.387328</td>\n",
       "      <td>3.507160</td>\n",
       "      <td>4.163499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.529196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.144046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001239</th>\n",
       "      <td>4.161888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.267349</td>\n",
       "      <td>2.572890</td>\n",
       "      <td>3.729009</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.903038</td>\n",
       "      <td>6.166715</td>\n",
       "      <td>4.543496</td>\n",
       "      <td>3.340562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.712321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.305241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001306</th>\n",
       "      <td>3.581351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.933809</td>\n",
       "      <td>1.859970</td>\n",
       "      <td>3.560715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.979111</td>\n",
       "      <td>4.281698</td>\n",
       "      <td>3.405992</td>\n",
       "      <td>4.519164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.444766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.292782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.650765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001307</th>\n",
       "      <td>3.988230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.027464</td>\n",
       "      <td>1.835924</td>\n",
       "      <td>3.704872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485427</td>\n",
       "      <td>5.891905</td>\n",
       "      <td>3.667892</td>\n",
       "      <td>4.064366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.727648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.426265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001318</th>\n",
       "      <td>3.983678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.610287</td>\n",
       "      <td>2.330558</td>\n",
       "      <td>3.770829</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>1.855990</td>\n",
       "      <td>7.816856</td>\n",
       "      <td>5.713421</td>\n",
       "      <td>4.729553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.300490</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.689299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001321</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.280771</td>\n",
       "      <td>3.393691</td>\n",
       "      <td>4.115200</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>4.385431</td>\n",
       "      <td>5.188638</td>\n",
       "      <td>5.536675</td>\n",
       "      <td>5.106013</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.142413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.446256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007 rows × 30805 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TSPAN6  TNMD      DPM1     SCYL3  C1orf112       FGR  \\\n",
       "improve_sample_id                                                           \n",
       "ACH-000016         4.189825   0.0  6.126601  2.114367  2.235727  0.000000   \n",
       "ACH-000032         0.070389   0.0  5.883376  3.549669  5.307064  0.028569   \n",
       "ACH-000033         4.682573   0.0  6.949185  1.823749  3.837943  0.028569   \n",
       "ACH-000043         3.499527   0.0  6.612647  1.952334  2.726831  0.070389   \n",
       "ACH-000049         4.262283   0.0  6.536985  2.087463  4.051372  0.028569   \n",
       "...                     ...   ...       ...       ...       ...       ...   \n",
       "ACH-001239         4.161888   0.0  6.267349  2.572890  3.729009  0.163499   \n",
       "ACH-001306         3.581351   0.0  6.933809  1.859970  3.560715  0.000000   \n",
       "ACH-001307         3.988230   0.0  7.027464  1.835924  3.704872  0.000000   \n",
       "ACH-001318         3.983678   0.0  6.610287  2.330558  3.770829  0.056584   \n",
       "ACH-001321         1.000000   0.0  6.280771  3.393691  4.115200  0.028569   \n",
       "\n",
       "                        CFH     FUCA2      GCLC      NFYA  ...     PANO1  \\\n",
       "improve_sample_id                                          ...             \n",
       "ACH-000016         7.094553  5.907131  6.029453  3.669027  ...  0.443607   \n",
       "ACH-000032         0.070389  0.286881  4.758090  5.542568  ...  1.189034   \n",
       "ACH-000033         0.790772  6.224002  4.825786  4.408032  ...  0.963474   \n",
       "ACH-000043         5.630813  6.098664  5.210623  3.148934  ...  0.895303   \n",
       "ACH-000049         2.807355  6.387328  3.507160  4.163499  ...  0.367371   \n",
       "...                     ...       ...       ...       ...  ...       ...   \n",
       "ACH-001239         0.903038  6.166715  4.543496  3.340562  ...  0.584963   \n",
       "ACH-001306         3.979111  4.281698  3.405992  4.519164  ...  1.049631   \n",
       "ACH-001307         0.485427  5.891905  3.667892  4.064366  ...  0.704872   \n",
       "ACH-001318         1.855990  7.816856  5.713421  4.729553  ...  0.925999   \n",
       "ACH-001321         4.385431  5.188638  5.536675  5.106013  ...  1.500802   \n",
       "\n",
       "                       XGY2  FLJ43315  LOC105377369    PRRC2B    UGT1A3  \\\n",
       "improve_sample_id                                                         \n",
       "ACH-000016         0.000000  0.000000      0.000000  5.838700  0.321928   \n",
       "ACH-000032         0.238787  0.042644      0.000000  7.320124  0.000000   \n",
       "ACH-000033         0.111031  0.367371      0.070389  5.638364  0.000000   \n",
       "ACH-000043         0.056584  0.028569      0.000000  4.616475  0.000000   \n",
       "ACH-000049         0.000000  0.000000      0.000000  5.529196  0.000000   \n",
       "...                     ...       ...           ...       ...       ...   \n",
       "ACH-001239         0.000000  0.000000      0.000000  5.712321  0.000000   \n",
       "ACH-001306         0.000000  0.000000      0.000000  6.444766  0.000000   \n",
       "ACH-001307         0.000000  0.014355      0.000000  6.727648  0.000000   \n",
       "ACH-001318         0.084064  0.150560      0.000000  5.300490  0.042644   \n",
       "ACH-001321         0.000000  0.150560      0.000000  6.142413  0.000000   \n",
       "\n",
       "                     UGT1A5      F8A2  LOC105377063      F8A1  \n",
       "improve_sample_id                                              \n",
       "ACH-000016         0.163499  0.042644      0.000000  3.356144  \n",
       "ACH-000032         0.000000  0.000000      0.000000  5.493455  \n",
       "ACH-000033         0.000000  0.000000      0.704872  3.270529  \n",
       "ACH-000043         0.000000  0.000000      0.000000  3.726831  \n",
       "ACH-000049         0.000000  0.000000      0.000000  4.144046  \n",
       "...                     ...       ...           ...       ...  \n",
       "ACH-001239         0.000000  0.000000      0.000000  4.305241  \n",
       "ACH-001306         0.000000  1.292782      0.000000  4.650765  \n",
       "ACH-001307         0.000000  0.000000      0.000000  4.426265  \n",
       "ACH-001318         0.000000  1.084064      0.000000  2.689299  \n",
       "ACH-001321         0.000000  0.000000      0.000000  4.446256  \n",
       "\n",
       "[1007 rows x 30805 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2976619/2325377014.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  response = pd.read_csv(\"data/GDSC/response.tsv\", sep = '\\t')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>improve_sample_id</th>\n",
       "      <th>improve_chem_id</th>\n",
       "      <th>study</th>\n",
       "      <th>auc</th>\n",
       "      <th>ic50</th>\n",
       "      <th>ec50</th>\n",
       "      <th>ec50se</th>\n",
       "      <th>r2fit</th>\n",
       "      <th>einf</th>\n",
       "      <th>hs</th>\n",
       "      <th>aac1</th>\n",
       "      <th>auc1</th>\n",
       "      <th>dss1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_749</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>5.6600</td>\n",
       "      <td>5.6600</td>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6669</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_1326</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0230</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_490</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>7.5460</td>\n",
       "      <td>7.5510</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>1.3380</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>0.6605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_558</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>5.1980</td>\n",
       "      <td>5.1980</td>\n",
       "      <td>11.7100</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.0291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_895</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>7.0930</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>1.0150</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587704</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_470</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8900</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587705</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_343</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>3.0070</td>\n",
       "      <td>3.0070</td>\n",
       "      <td>46.7600</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587706</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_1190</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4040</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587707</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_89</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>233.0000</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587708</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_36</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>4.7880</td>\n",
       "      <td>4.7880</td>\n",
       "      <td>2.8020</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587709 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source improve_sample_id improve_chem_id     study     auc    ic50  \\\n",
       "0         CCLE        ACH-000956        Drug_749  fake_exp  0.7153  5.6600   \n",
       "1         CCLE        ACH-000956       Drug_1326  fake_exp  0.9579     NaN   \n",
       "2         CCLE        ACH-000956        Drug_490  fake_exp  0.4130  7.5460   \n",
       "3         CCLE        ACH-000956        Drug_558  fake_exp  0.8004  5.1980   \n",
       "4         CCLE        ACH-000956        Drug_895  fake_exp  0.5071  7.0930   \n",
       "...        ...               ...             ...       ...     ...     ...   \n",
       "587704  GDSCv2        ACH-000475        Drug_470     19498  0.9548     NaN   \n",
       "587705  GDSCv2        ACH-000475        Drug_343     19498  0.8190  3.0070   \n",
       "587706  GDSCv2        ACH-000475       Drug_1190     19498  0.9105     NaN   \n",
       "587707  GDSCv2        ACH-000475         Drug_89     19498  0.9566  0.2428   \n",
       "587708  GDSCv2        ACH-000475         Drug_36     19498  0.8426  4.7880   \n",
       "\n",
       "          ec50    ec50se   r2fit    einf      hs    aac1    auc1    dss1  \n",
       "0       5.6600    0.6867  0.9533  0.0000  0.6669  0.2240  0.7760  0.1661  \n",
       "1       7.0230    0.7111  0.4332  0.9164  4.0000  0.0459  0.9541  0.0000  \n",
       "2       7.5510    0.0385  0.9948  0.0082  1.3380  0.6909  0.3091  0.6605  \n",
       "3       5.1980   11.7100  0.9944  0.0000  4.0000  0.0392  0.9608  0.0291  \n",
       "4       7.1490    0.3175  0.8069  0.0607  1.0150  0.5470  0.4530  0.5037  \n",
       "...        ...       ...     ...     ...     ...     ...     ...     ...  \n",
       "587704  7.8900    0.0000 -0.0000  0.9096  0.0000  0.0452  0.9548  0.0000  \n",
       "587705  3.0070   46.7600  0.4604  0.0000  0.1818  0.1943  0.8057  0.1047  \n",
       "587706  3.4040    0.0000 -0.0000  0.8209  0.0000  0.0895  0.9105  0.0000  \n",
       "587707  0.2428  233.0000  0.1946  0.0000  0.2200  0.0438  0.9562  0.0000  \n",
       "587708  4.7880    2.8020  0.8616  0.0000  0.6938  0.1111  0.8889  0.0573  \n",
       "\n",
       "[587709 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_csv(\"data/GDSC/response.tsv\", sep = '\\t')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc_info = pd.read_csv(\"data/GDSC/GDSC_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>CellLineName</th>\n",
       "      <th>StrippedCellLineName</th>\n",
       "      <th>Age</th>\n",
       "      <th>SourceType</th>\n",
       "      <th>SangerModelID</th>\n",
       "      <th>RRID</th>\n",
       "      <th>DepmapModelType</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>...</th>\n",
       "      <th>PublicComments</th>\n",
       "      <th>WTSIMasterCellID</th>\n",
       "      <th>EngineeredModel</th>\n",
       "      <th>TreatmentStatus</th>\n",
       "      <th>OnboardedMedia</th>\n",
       "      <th>PlateCoating</th>\n",
       "      <th>OncotreeCode</th>\n",
       "      <th>OncotreeSubtype</th>\n",
       "      <th>OncotreePrimaryDisease</th>\n",
       "      <th>OncotreeLineage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>PT-gj46wT</td>\n",
       "      <td>NIH:OVCAR-3</td>\n",
       "      <td>NIHOVCAR3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>SIDM00105</td>\n",
       "      <td>CVCL_0465</td>\n",
       "      <td>HGSOC</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2201.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-001-041</td>\n",
       "      <td>None</td>\n",
       "      <td>HGSOC</td>\n",
       "      <td>High-Grade Serous Ovarian Cancer</td>\n",
       "      <td>Ovarian Epithelial Tumor</td>\n",
       "      <td>Ovary/Fallopian Tube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>PT-5qa3uk</td>\n",
       "      <td>HL-60</td>\n",
       "      <td>HL60</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>SIDM00829</td>\n",
       "      <td>CVCL_0002</td>\n",
       "      <td>AML</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-005-001</td>\n",
       "      <td>None</td>\n",
       "      <td>AML</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000003</td>\n",
       "      <td>PT-puKIyc</td>\n",
       "      <td>CACO2</td>\n",
       "      <td>CACO2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>SIDM00891</td>\n",
       "      <td>CVCL_0025</td>\n",
       "      <td>COAD</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MF-015-009</td>\n",
       "      <td>None</td>\n",
       "      <td>COAD</td>\n",
       "      <td>Colon Adenocarcinoma</td>\n",
       "      <td>Colorectal Adenocarcinoma</td>\n",
       "      <td>Bowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>PT-q4K2cp</td>\n",
       "      <td>HEL</td>\n",
       "      <td>HEL</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>SIDM00594</td>\n",
       "      <td>CVCL_0001</td>\n",
       "      <td>AML</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>783.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Post-treatment</td>\n",
       "      <td>MF-001-001</td>\n",
       "      <td>None</td>\n",
       "      <td>AML</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000005</td>\n",
       "      <td>PT-q4K2cp</td>\n",
       "      <td>HEL 92.1.7</td>\n",
       "      <td>HEL9217</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>SIDM00593</td>\n",
       "      <td>CVCL_2481</td>\n",
       "      <td>AML</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-001-001</td>\n",
       "      <td>None</td>\n",
       "      <td>AML</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>ACH-002968</td>\n",
       "      <td>PT-pjhrsc</td>\n",
       "      <td>CCLF_UPGI_0041_T</td>\n",
       "      <td>CCLFUPGI0041T</td>\n",
       "      <td>53.0</td>\n",
       "      <td>CCLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAD</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-031-002</td>\n",
       "      <td>None</td>\n",
       "      <td>STAD</td>\n",
       "      <td>Stomach Adenocarcinoma</td>\n",
       "      <td>Esophagogastric Adenocarcinoma</td>\n",
       "      <td>Esophagus/Stomach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>ACH-002972</td>\n",
       "      <td>PT-dkXZB1</td>\n",
       "      <td>CCLF_UPGI_0085_T</td>\n",
       "      <td>CCLFUPGI0085T</td>\n",
       "      <td>57.0</td>\n",
       "      <td>CCLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAD</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-031-002</td>\n",
       "      <td>None</td>\n",
       "      <td>STAD</td>\n",
       "      <td>Stomach Adenocarcinoma</td>\n",
       "      <td>Esophagogastric Adenocarcinoma</td>\n",
       "      <td>Esophagus/Stomach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>ACH-002979</td>\n",
       "      <td>PT-lyHTzo</td>\n",
       "      <td>CCLF_UPGI_0101_T</td>\n",
       "      <td>CCLFUPGI0101T</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CCLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DSTAD</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-031-002</td>\n",
       "      <td>None</td>\n",
       "      <td>DSTAD</td>\n",
       "      <td>Diffuse Type Stomach Adenocarcinoma</td>\n",
       "      <td>Esophagogastric Adenocarcinoma</td>\n",
       "      <td>Esophagus/Stomach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>ACH-002981</td>\n",
       "      <td>PT-Z9akXf</td>\n",
       "      <td>CCLF_UPGI_0027_T</td>\n",
       "      <td>CCLFUPGI0027T</td>\n",
       "      <td>78.0</td>\n",
       "      <td>CCLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESCA</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-031-002</td>\n",
       "      <td>None</td>\n",
       "      <td>ESCA</td>\n",
       "      <td>Esophageal Adenocarcinoma</td>\n",
       "      <td>Esophagogastric Adenocarcinoma</td>\n",
       "      <td>Esophagus/Stomach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>ACH-003071</td>\n",
       "      <td>PT-LAGmLq</td>\n",
       "      <td>NCI-H748</td>\n",
       "      <td>NCIH748</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVCL_1588</td>\n",
       "      <td>SCLC</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-001-001</td>\n",
       "      <td>None</td>\n",
       "      <td>SCLC</td>\n",
       "      <td>Small Cell Lung Cancer</td>\n",
       "      <td>Lung Neuroendocrine Tumor</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1864 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ModelID  PatientID      CellLineName StrippedCellLineName   Age  \\\n",
       "0     ACH-000001  PT-gj46wT       NIH:OVCAR-3            NIHOVCAR3  60.0   \n",
       "1     ACH-000002  PT-5qa3uk             HL-60                 HL60  36.0   \n",
       "2     ACH-000003  PT-puKIyc             CACO2                CACO2  72.0   \n",
       "3     ACH-000004  PT-q4K2cp               HEL                  HEL  30.0   \n",
       "4     ACH-000005  PT-q4K2cp        HEL 92.1.7              HEL9217  30.0   \n",
       "...          ...        ...               ...                  ...   ...   \n",
       "1859  ACH-002968  PT-pjhrsc  CCLF_UPGI_0041_T        CCLFUPGI0041T  53.0   \n",
       "1860  ACH-002972  PT-dkXZB1  CCLF_UPGI_0085_T        CCLFUPGI0085T  57.0   \n",
       "1861  ACH-002979  PT-lyHTzo  CCLF_UPGI_0101_T        CCLFUPGI0101T  60.0   \n",
       "1862  ACH-002981  PT-Z9akXf  CCLF_UPGI_0027_T        CCLFUPGI0027T  78.0   \n",
       "1863  ACH-003071  PT-LAGmLq          NCI-H748              NCIH748  62.0   \n",
       "\n",
       "      SourceType SangerModelID       RRID DepmapModelType AgeCategory  ...  \\\n",
       "0     Commercial     SIDM00105  CVCL_0465           HGSOC       Adult  ...   \n",
       "1     Commercial     SIDM00829  CVCL_0002             AML       Adult  ...   \n",
       "2     Commercial     SIDM00891  CVCL_0025            COAD       Adult  ...   \n",
       "3     Commercial     SIDM00594  CVCL_0001             AML       Adult  ...   \n",
       "4     Commercial     SIDM00593  CVCL_2481             AML       Adult  ...   \n",
       "...          ...           ...        ...             ...         ...  ...   \n",
       "1859        CCLF           NaN        NaN            STAD       Adult  ...   \n",
       "1860        CCLF           NaN        NaN            STAD       Adult  ...   \n",
       "1861        CCLF           NaN        NaN           DSTAD       Adult  ...   \n",
       "1862        CCLF           NaN        NaN            ESCA       Adult  ...   \n",
       "1863  Commercial           NaN  CVCL_1588            SCLC       Adult  ...   \n",
       "\n",
       "     PublicComments WTSIMasterCellID EngineeredModel TreatmentStatus  \\\n",
       "0               NaN           2201.0             NaN             NaN   \n",
       "1               NaN             55.0             NaN             NaN   \n",
       "2               NaN              NaN             NaN         Unknown   \n",
       "3               NaN            783.0             NaN  Post-treatment   \n",
       "4               NaN              NaN             NaN             NaN   \n",
       "...             ...              ...             ...             ...   \n",
       "1859            NaN              NaN             NaN             NaN   \n",
       "1860            NaN              NaN             NaN             NaN   \n",
       "1861            NaN              NaN             NaN             NaN   \n",
       "1862            NaN              NaN             NaN             NaN   \n",
       "1863            NaN              NaN             NaN             NaN   \n",
       "\n",
       "     OnboardedMedia PlateCoating OncotreeCode  \\\n",
       "0        MF-001-041         None        HGSOC   \n",
       "1        MF-005-001         None          AML   \n",
       "2        MF-015-009         None         COAD   \n",
       "3        MF-001-001         None          AML   \n",
       "4        MF-001-001         None          AML   \n",
       "...             ...          ...          ...   \n",
       "1859     MF-031-002         None         STAD   \n",
       "1860     MF-031-002         None         STAD   \n",
       "1861     MF-031-002         None        DSTAD   \n",
       "1862     MF-031-002         None         ESCA   \n",
       "1863     MF-001-001         None         SCLC   \n",
       "\n",
       "                          OncotreeSubtype          OncotreePrimaryDisease  \\\n",
       "0        High-Grade Serous Ovarian Cancer        Ovarian Epithelial Tumor   \n",
       "1                  Acute Myeloid Leukemia          Acute Myeloid Leukemia   \n",
       "2                    Colon Adenocarcinoma       Colorectal Adenocarcinoma   \n",
       "3                  Acute Myeloid Leukemia          Acute Myeloid Leukemia   \n",
       "4                  Acute Myeloid Leukemia          Acute Myeloid Leukemia   \n",
       "...                                   ...                             ...   \n",
       "1859               Stomach Adenocarcinoma  Esophagogastric Adenocarcinoma   \n",
       "1860               Stomach Adenocarcinoma  Esophagogastric Adenocarcinoma   \n",
       "1861  Diffuse Type Stomach Adenocarcinoma  Esophagogastric Adenocarcinoma   \n",
       "1862            Esophageal Adenocarcinoma  Esophagogastric Adenocarcinoma   \n",
       "1863               Small Cell Lung Cancer       Lung Neuroendocrine Tumor   \n",
       "\n",
       "           OncotreeLineage  \n",
       "0     Ovary/Fallopian Tube  \n",
       "1                  Myeloid  \n",
       "2                    Bowel  \n",
       "3                  Myeloid  \n",
       "4                  Myeloid  \n",
       "...                    ...  \n",
       "1859     Esophagus/Stomach  \n",
       "1860     Esophagus/Stomach  \n",
       "1861     Esophagus/Stomach  \n",
       "1862     Esophagus/Stomach  \n",
       "1863                  Lung  \n",
       "\n",
       "[1864 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc = pd.merge(gene_express, gdsc_info, how=\"inner\", left_on=[\"improve_sample_id\"], right_on=['ModelID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>GCLC</th>\n",
       "      <th>NFYA</th>\n",
       "      <th>...</th>\n",
       "      <th>PublicComments</th>\n",
       "      <th>WTSIMasterCellID</th>\n",
       "      <th>EngineeredModel</th>\n",
       "      <th>TreatmentStatus</th>\n",
       "      <th>OnboardedMedia</th>\n",
       "      <th>PlateCoating</th>\n",
       "      <th>OncotreeCode</th>\n",
       "      <th>OncotreeSubtype</th>\n",
       "      <th>OncotreePrimaryDisease</th>\n",
       "      <th>OncotreeLineage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.189825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.126601</td>\n",
       "      <td>2.114367</td>\n",
       "      <td>2.235727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.094553</td>\n",
       "      <td>5.907131</td>\n",
       "      <td>6.029453</td>\n",
       "      <td>3.669027</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-001-001</td>\n",
       "      <td>None</td>\n",
       "      <td>CCRCC</td>\n",
       "      <td>Renal Clear Cell Carcinoma</td>\n",
       "      <td>Renal Cell Carcinoma</td>\n",
       "      <td>Kidney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.883376</td>\n",
       "      <td>3.549669</td>\n",
       "      <td>5.307064</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>4.758090</td>\n",
       "      <td>5.542568</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-treatment</td>\n",
       "      <td>MF-001-020</td>\n",
       "      <td>None</td>\n",
       "      <td>BLL</td>\n",
       "      <td>B-Lymphoblastic Leukemia/Lymphoma</td>\n",
       "      <td>B-Lymphoblastic Leukemia/Lymphoma</td>\n",
       "      <td>Lymphoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.682573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.949185</td>\n",
       "      <td>1.823749</td>\n",
       "      <td>3.837943</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>6.224002</td>\n",
       "      <td>4.825786</td>\n",
       "      <td>4.408032</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-001-014</td>\n",
       "      <td>None</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>Lung Adenocarcinoma</td>\n",
       "      <td>Non-Small Cell Lung Cancer</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.499527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.612647</td>\n",
       "      <td>1.952334</td>\n",
       "      <td>2.726831</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.630813</td>\n",
       "      <td>6.098664</td>\n",
       "      <td>5.210623</td>\n",
       "      <td>3.148934</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-002-001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fibroblast, Skin</td>\n",
       "      <td>Non-Cancerous</td>\n",
       "      <td>Fibroblast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.262283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.536985</td>\n",
       "      <td>2.087463</td>\n",
       "      <td>4.051372</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>6.387328</td>\n",
       "      <td>3.507160</td>\n",
       "      <td>4.163499</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Immortalized Embyonic Kidney Cells</td>\n",
       "      <td>Non-Cancerous</td>\n",
       "      <td>Kidney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>4.161888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.267349</td>\n",
       "      <td>2.572890</td>\n",
       "      <td>3.729009</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.903038</td>\n",
       "      <td>6.166715</td>\n",
       "      <td>4.543496</td>\n",
       "      <td>3.340562</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-002-001</td>\n",
       "      <td>None</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>Skin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>3.581351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.933809</td>\n",
       "      <td>1.859970</td>\n",
       "      <td>3.560715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.979111</td>\n",
       "      <td>4.281698</td>\n",
       "      <td>3.405992</td>\n",
       "      <td>4.519164</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-001-017</td>\n",
       "      <td>None</td>\n",
       "      <td>THAP</td>\n",
       "      <td>Anaplastic Thyroid Cancer</td>\n",
       "      <td>Anaplastic Thyroid Cancer</td>\n",
       "      <td>Thyroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>3.988230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.027464</td>\n",
       "      <td>1.835924</td>\n",
       "      <td>3.704872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485427</td>\n",
       "      <td>5.891905</td>\n",
       "      <td>3.667892</td>\n",
       "      <td>4.064366</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-015-002</td>\n",
       "      <td>None</td>\n",
       "      <td>THAP</td>\n",
       "      <td>Anaplastic Thyroid Cancer</td>\n",
       "      <td>Anaplastic Thyroid Cancer</td>\n",
       "      <td>Thyroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>3.983678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.610287</td>\n",
       "      <td>2.330558</td>\n",
       "      <td>3.770829</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>1.855990</td>\n",
       "      <td>7.816856</td>\n",
       "      <td>5.713421</td>\n",
       "      <td>4.729553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-002-001</td>\n",
       "      <td>None</td>\n",
       "      <td>HCC</td>\n",
       "      <td>Hepatocellular Carcinoma</td>\n",
       "      <td>Hepatocellular Carcinoma</td>\n",
       "      <td>Liver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.280771</td>\n",
       "      <td>3.393691</td>\n",
       "      <td>4.115200</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>4.385431</td>\n",
       "      <td>5.188638</td>\n",
       "      <td>5.536675</td>\n",
       "      <td>5.106013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MF-004-001</td>\n",
       "      <td>None</td>\n",
       "      <td>THME</td>\n",
       "      <td>Medullary Thyroid Cancer</td>\n",
       "      <td>Medullary Thyroid Cancer</td>\n",
       "      <td>Thyroid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007 rows × 30835 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TSPAN6  TNMD      DPM1     SCYL3  C1orf112       FGR       CFH  \\\n",
       "0     4.189825   0.0  6.126601  2.114367  2.235727  0.000000  7.094553   \n",
       "1     0.070389   0.0  5.883376  3.549669  5.307064  0.028569  0.070389   \n",
       "2     4.682573   0.0  6.949185  1.823749  3.837943  0.028569  0.790772   \n",
       "3     3.499527   0.0  6.612647  1.952334  2.726831  0.070389  5.630813   \n",
       "4     4.262283   0.0  6.536985  2.087463  4.051372  0.028569  2.807355   \n",
       "...        ...   ...       ...       ...       ...       ...       ...   \n",
       "1002  4.161888   0.0  6.267349  2.572890  3.729009  0.163499  0.903038   \n",
       "1003  3.581351   0.0  6.933809  1.859970  3.560715  0.000000  3.979111   \n",
       "1004  3.988230   0.0  7.027464  1.835924  3.704872  0.000000  0.485427   \n",
       "1005  3.983678   0.0  6.610287  2.330558  3.770829  0.056584  1.855990   \n",
       "1006  1.000000   0.0  6.280771  3.393691  4.115200  0.028569  4.385431   \n",
       "\n",
       "         FUCA2      GCLC      NFYA  ...  PublicComments  WTSIMasterCellID  \\\n",
       "0     5.907131  6.029453  3.669027  ...             NaN               NaN   \n",
       "1     0.286881  4.758090  5.542568  ...             NaN               NaN   \n",
       "2     6.224002  4.825786  4.408032  ...             NaN               NaN   \n",
       "3     6.098664  5.210623  3.148934  ...             NaN               NaN   \n",
       "4     6.387328  3.507160  4.163499  ...             NaN               NaN   \n",
       "...        ...       ...       ...  ...             ...               ...   \n",
       "1002  6.166715  4.543496  3.340562  ...             NaN               NaN   \n",
       "1003  4.281698  3.405992  4.519164  ...             NaN             433.0   \n",
       "1004  5.891905  3.667892  4.064366  ...             NaN             868.0   \n",
       "1005  7.816856  5.713421  4.729553  ...             NaN               NaN   \n",
       "1006  5.188638  5.536675  5.106013  ...             NaN               NaN   \n",
       "\n",
       "      EngineeredModel  TreatmentStatus  OnboardedMedia  PlateCoating  \\\n",
       "0                 NaN              NaN      MF-001-001          None   \n",
       "1                 NaN    Pre-treatment      MF-001-020          None   \n",
       "2                 NaN              NaN      MF-001-014          None   \n",
       "3                 NaN              NaN      MF-002-001          None   \n",
       "4                 NaN              NaN             NaN          None   \n",
       "...               ...              ...             ...           ...   \n",
       "1002              NaN              NaN      MF-002-001          None   \n",
       "1003              NaN              NaN      MF-001-017          None   \n",
       "1004              NaN              NaN      MF-015-002          None   \n",
       "1005              NaN              NaN      MF-002-001          None   \n",
       "1006              NaN              NaN      MF-004-001          None   \n",
       "\n",
       "      OncotreeCode                     OncotreeSubtype  \\\n",
       "0            CCRCC          Renal Clear Cell Carcinoma   \n",
       "1              BLL   B-Lymphoblastic Leukemia/Lymphoma   \n",
       "2             LUAD                 Lung Adenocarcinoma   \n",
       "3              NaN                    Fibroblast, Skin   \n",
       "4              NaN  Immortalized Embyonic Kidney Cells   \n",
       "...            ...                                 ...   \n",
       "1002           MEL                            Melanoma   \n",
       "1003          THAP           Anaplastic Thyroid Cancer   \n",
       "1004          THAP           Anaplastic Thyroid Cancer   \n",
       "1005           HCC            Hepatocellular Carcinoma   \n",
       "1006          THME            Medullary Thyroid Cancer   \n",
       "\n",
       "                 OncotreePrimaryDisease  OncotreeLineage  \n",
       "0                  Renal Cell Carcinoma           Kidney  \n",
       "1     B-Lymphoblastic Leukemia/Lymphoma         Lymphoid  \n",
       "2            Non-Small Cell Lung Cancer             Lung  \n",
       "3                         Non-Cancerous       Fibroblast  \n",
       "4                         Non-Cancerous           Kidney  \n",
       "...                                 ...              ...  \n",
       "1002                           Melanoma             Skin  \n",
       "1003          Anaplastic Thyroid Cancer          Thyroid  \n",
       "1004          Anaplastic Thyroid Cancer          Thyroid  \n",
       "1005           Hepatocellular Carcinoma            Liver  \n",
       "1006           Medullary Thyroid Cancer          Thyroid  \n",
       "\n",
       "[1007 rows x 30835 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc_x = gdsc.loc[:, gene_express.columns]\n",
    "gdsc_y = gdsc.loc[:, 'DepmapModelType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>GCLC</th>\n",
       "      <th>NFYA</th>\n",
       "      <th>...</th>\n",
       "      <th>PANO1</th>\n",
       "      <th>XGY2</th>\n",
       "      <th>FLJ43315</th>\n",
       "      <th>LOC105377369</th>\n",
       "      <th>PRRC2B</th>\n",
       "      <th>UGT1A3</th>\n",
       "      <th>UGT1A5</th>\n",
       "      <th>F8A2</th>\n",
       "      <th>LOC105377063</th>\n",
       "      <th>F8A1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.189825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.126601</td>\n",
       "      <td>2.114367</td>\n",
       "      <td>2.235727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.094553</td>\n",
       "      <td>5.907131</td>\n",
       "      <td>6.029453</td>\n",
       "      <td>3.669027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.838700</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.356144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.883376</td>\n",
       "      <td>3.549669</td>\n",
       "      <td>5.307064</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>4.758090</td>\n",
       "      <td>5.542568</td>\n",
       "      <td>...</td>\n",
       "      <td>1.189034</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.320124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.493455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.682573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.949185</td>\n",
       "      <td>1.823749</td>\n",
       "      <td>3.837943</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>6.224002</td>\n",
       "      <td>4.825786</td>\n",
       "      <td>4.408032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963474</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.367371</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.638364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>3.270529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.499527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.612647</td>\n",
       "      <td>1.952334</td>\n",
       "      <td>2.726831</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.630813</td>\n",
       "      <td>6.098664</td>\n",
       "      <td>5.210623</td>\n",
       "      <td>3.148934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895303</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.616475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.726831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.262283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.536985</td>\n",
       "      <td>2.087463</td>\n",
       "      <td>4.051372</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>6.387328</td>\n",
       "      <td>3.507160</td>\n",
       "      <td>4.163499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.529196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.144046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>4.161888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.267349</td>\n",
       "      <td>2.572890</td>\n",
       "      <td>3.729009</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.903038</td>\n",
       "      <td>6.166715</td>\n",
       "      <td>4.543496</td>\n",
       "      <td>3.340562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.712321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.305241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>3.581351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.933809</td>\n",
       "      <td>1.859970</td>\n",
       "      <td>3.560715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.979111</td>\n",
       "      <td>4.281698</td>\n",
       "      <td>3.405992</td>\n",
       "      <td>4.519164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.444766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.292782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.650765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>3.988230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.027464</td>\n",
       "      <td>1.835924</td>\n",
       "      <td>3.704872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485427</td>\n",
       "      <td>5.891905</td>\n",
       "      <td>3.667892</td>\n",
       "      <td>4.064366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.727648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.426265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>3.983678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.610287</td>\n",
       "      <td>2.330558</td>\n",
       "      <td>3.770829</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>1.855990</td>\n",
       "      <td>7.816856</td>\n",
       "      <td>5.713421</td>\n",
       "      <td>4.729553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.300490</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.689299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.280771</td>\n",
       "      <td>3.393691</td>\n",
       "      <td>4.115200</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>4.385431</td>\n",
       "      <td>5.188638</td>\n",
       "      <td>5.536675</td>\n",
       "      <td>5.106013</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.142413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.446256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007 rows × 30805 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TSPAN6  TNMD      DPM1     SCYL3  C1orf112       FGR       CFH  \\\n",
       "0     4.189825   0.0  6.126601  2.114367  2.235727  0.000000  7.094553   \n",
       "1     0.070389   0.0  5.883376  3.549669  5.307064  0.028569  0.070389   \n",
       "2     4.682573   0.0  6.949185  1.823749  3.837943  0.028569  0.790772   \n",
       "3     3.499527   0.0  6.612647  1.952334  2.726831  0.070389  5.630813   \n",
       "4     4.262283   0.0  6.536985  2.087463  4.051372  0.028569  2.807355   \n",
       "...        ...   ...       ...       ...       ...       ...       ...   \n",
       "1002  4.161888   0.0  6.267349  2.572890  3.729009  0.163499  0.903038   \n",
       "1003  3.581351   0.0  6.933809  1.859970  3.560715  0.000000  3.979111   \n",
       "1004  3.988230   0.0  7.027464  1.835924  3.704872  0.000000  0.485427   \n",
       "1005  3.983678   0.0  6.610287  2.330558  3.770829  0.056584  1.855990   \n",
       "1006  1.000000   0.0  6.280771  3.393691  4.115200  0.028569  4.385431   \n",
       "\n",
       "         FUCA2      GCLC      NFYA  ...     PANO1      XGY2  FLJ43315  \\\n",
       "0     5.907131  6.029453  3.669027  ...  0.443607  0.000000  0.000000   \n",
       "1     0.286881  4.758090  5.542568  ...  1.189034  0.238787  0.042644   \n",
       "2     6.224002  4.825786  4.408032  ...  0.963474  0.111031  0.367371   \n",
       "3     6.098664  5.210623  3.148934  ...  0.895303  0.056584  0.028569   \n",
       "4     6.387328  3.507160  4.163499  ...  0.367371  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1002  6.166715  4.543496  3.340562  ...  0.584963  0.000000  0.000000   \n",
       "1003  4.281698  3.405992  4.519164  ...  1.049631  0.000000  0.000000   \n",
       "1004  5.891905  3.667892  4.064366  ...  0.704872  0.000000  0.014355   \n",
       "1005  7.816856  5.713421  4.729553  ...  0.925999  0.084064  0.150560   \n",
       "1006  5.188638  5.536675  5.106013  ...  1.500802  0.000000  0.150560   \n",
       "\n",
       "      LOC105377369    PRRC2B    UGT1A3    UGT1A5      F8A2  LOC105377063  \\\n",
       "0         0.000000  5.838700  0.321928  0.163499  0.042644      0.000000   \n",
       "1         0.000000  7.320124  0.000000  0.000000  0.000000      0.000000   \n",
       "2         0.070389  5.638364  0.000000  0.000000  0.000000      0.704872   \n",
       "3         0.000000  4.616475  0.000000  0.000000  0.000000      0.000000   \n",
       "4         0.000000  5.529196  0.000000  0.000000  0.000000      0.000000   \n",
       "...            ...       ...       ...       ...       ...           ...   \n",
       "1002      0.000000  5.712321  0.000000  0.000000  0.000000      0.000000   \n",
       "1003      0.000000  6.444766  0.000000  0.000000  1.292782      0.000000   \n",
       "1004      0.000000  6.727648  0.000000  0.000000  0.000000      0.000000   \n",
       "1005      0.000000  5.300490  0.042644  0.000000  1.084064      0.000000   \n",
       "1006      0.000000  6.142413  0.000000  0.000000  0.000000      0.000000   \n",
       "\n",
       "          F8A1  \n",
       "0     3.356144  \n",
       "1     5.493455  \n",
       "2     3.270529  \n",
       "3     3.726831  \n",
       "4     4.144046  \n",
       "...        ...  \n",
       "1002  4.305241  \n",
       "1003  4.650765  \n",
       "1004  4.426265  \n",
       "1005  2.689299  \n",
       "1006  4.446256  \n",
       "\n",
       "[1007 rows x 30805 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         CCRCC\n",
       "1           BLL\n",
       "2          LUAD\n",
       "3       ZFIBSKI\n",
       "4       ZIMMEKC\n",
       "         ...   \n",
       "1002        MEL\n",
       "1003       THAP\n",
       "1004       THAP\n",
       "1005        HCC\n",
       "1006       THME\n",
       "Name: DepmapModelType, Length: 1007, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsc_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cell lines = 1225\n",
      "Total number of drugs = 684\n",
      "There are 3008 genes\n",
      "There are 1 roots: GO:0008150\n",
      "There are 2086 terms\n",
      "There are 1 connected componenets\n"
     ]
    }
   ],
   "source": [
    "training_file = \"data/drugcell_train.txt\"\n",
    "testing_file = \"data/drugcell_test.txt\"\n",
    "val_file = \"data/drugcell_val.txt\"\n",
    "cell2id_file = \"data/cell2ind.txt\"\n",
    "drug2id_file = \"data/drug2ind.txt\"\n",
    "genotype_file = \"data/cell2mutation.txt\"\n",
    "fingerprint_file = \"data/drug2fingerprint.txt\"\n",
    "onto_file = \"data/drugcell_ont.txt\"\n",
    "gene2id_file = \"data/gene2ind.txt\"\n",
    "\n",
    "train_data, feature_dict, cell2id_mapping, drug2id_mapping = prepare_train_data(training_file, \n",
    "                                                                  testing_file, cell2id_file, \n",
    "                                                                  drug2id_file)\n",
    "\n",
    "gene2id_mapping = load_mapping(gene2id_file)\n",
    "\n",
    "# load cell/drug features\n",
    "cell_features = np.genfromtxt(genotype_file, delimiter=',')\n",
    "drug_features = np.genfromtxt(fingerprint_file, delimiter=',')\n",
    "\n",
    "num_cells = len(cell2id_mapping)\n",
    "num_drugs = len(drug2id_mapping)\n",
    "num_genes = len(gene2id_mapping)\n",
    "drug_dim = len(drug_features[0,:])\n",
    "\n",
    "# load ontology\n",
    "dG, root, term_size_map, \\\n",
    "    term_direct_gene_map = load_ontology(onto_file, \n",
    "                                         gene2id_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersect of DCell and GDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2983"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(gene2id_mapping.keys()) & set(gdsc_x.columns)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align gene id with GDCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_list = list(set(gene2id_mapping.keys()) & set(gdsc_x.columns))\n",
    "gdsc_tensor = torch.zeros(gdsc_x.shape[0], num_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in gene_intersect_list:\n",
    "    idx = gene2id_mapping[gene]\n",
    "    gdsc_tensor[:,idx] = torch.tensor(gdsc_x[gene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LUAD             74\n",
       "COAD             50\n",
       "SCLC             48\n",
       "GB               42\n",
       "PAAD             38\n",
       "                 ..\n",
       "STAS              1\n",
       "AMLGATA2MECOM     1\n",
       "UCCC              1\n",
       "CLLSLL            1\n",
       "THME              1\n",
       "Name: DepmapModelType, Length: 138, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdsc_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(gdsc_y.value_counts() >1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_2_idx = {}\n",
    "idx_2_cancer = {}\n",
    "cancer_type_idx = []\n",
    "\n",
    "i = 0\n",
    "for cancer in gdsc_y:\n",
    "    if cancer not in cancer_2_idx:\n",
    "        cancer_2_idx[cancer] = i\n",
    "        idx_2_cancer[i] = cancer\n",
    "        cancer_type_idx.append(i)\n",
    "        \n",
    "        i += 1\n",
    "    else:\n",
    "        cancer_type_idx.append(cancer_2_idx[cancer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CCRCC': 0,\n",
       " 'BLL': 1,\n",
       " 'LUAD': 2,\n",
       " 'ZFIBSKI': 3,\n",
       " 'ZIMMEKC': 4,\n",
       " 'RMS': 5,\n",
       " 'ZIMMLUNG': 6,\n",
       " 'MCL': 7,\n",
       " 'ZFIBBON': 8,\n",
       " 'CML': 9,\n",
       " 'MTNN': 10,\n",
       " 'ZFIBSOF': 11,\n",
       " 'AMLGATA2MECOM': 12,\n",
       " 'COAD': 13,\n",
       " 'PAAD': 14,\n",
       " 'STAD': 15,\n",
       " 'ATLL': 16,\n",
       " 'ZFIBLYM': 17,\n",
       " 'DLBCLNOS': 18,\n",
       " 'ABC': 19,\n",
       " 'AML': 20,\n",
       " 'ZIMMEPCP': 21,\n",
       " 'ATRT': 22,\n",
       " 'UCEC': 23,\n",
       " 'SCLC': 24,\n",
       " 'ESCA': 25,\n",
       " 'ZFIBBRE': 26,\n",
       " 'TSTAD': 27,\n",
       " 'ZFIBUPA': 28,\n",
       " 'BRCNOS': 29,\n",
       " 'GB': 30,\n",
       " 'MOV': 31,\n",
       " 'RCC': 32,\n",
       " 'CHS': 33,\n",
       " 'PCM': 34,\n",
       " 'ZIMMOV': 35,\n",
       " 'ZFIBLUN': 36,\n",
       " 'MRT': 37,\n",
       " 'LUSC': 38,\n",
       " 'AMKL': 39,\n",
       " 'MYCF': 40,\n",
       " 'MNG': 41,\n",
       " 'HGSOC': 42,\n",
       " 'ZIMMBR': 43,\n",
       " 'PLEMESO': 44,\n",
       " 'PAASC': 45,\n",
       " 'OCSC': 46,\n",
       " 'ESCC': 47,\n",
       " 'BLCA': 48,\n",
       " 'MEL': 49,\n",
       " 'IHCH': 50,\n",
       " 'LCLC': 51,\n",
       " 'ZFIBCOL': 52,\n",
       " 'PRAD': 53,\n",
       " 'AM': 54,\n",
       " 'AMOL': 55,\n",
       " 'BRCA': 56,\n",
       " 'NSCLC': 57,\n",
       " 'SARCNOS': 58,\n",
       " 'ES': 59,\n",
       " 'ASTR': 60,\n",
       " 'ILC': 61,\n",
       " 'PRCC': 62,\n",
       " 'EOV': 63,\n",
       " 'ALCLALKP': 64,\n",
       " 'FIBS': 65,\n",
       " 'MBL': 66,\n",
       " 'THFO': 67,\n",
       " 'BLLBCRABL1': 68,\n",
       " 'ODG': 69,\n",
       " 'HL': 70,\n",
       " 'CMLBCRABL1': 71,\n",
       " 'NBL': 72,\n",
       " 'OS': 73,\n",
       " 'ZFIBURT': 74,\n",
       " 'SOC': 75,\n",
       " 'PLBMESO': 76,\n",
       " 'IDC': 77,\n",
       " 'ARMS': 78,\n",
       " 'TLL': 79,\n",
       " 'SCCO': 80,\n",
       " 'ERMS': 81,\n",
       " 'GBAD': 82,\n",
       " 'LMS': 83,\n",
       " 'PLSMESO': 84,\n",
       " 'BL': 85,\n",
       " 'HNSC': 86,\n",
       " 'THAP': 87,\n",
       " 'PRSCC': 88,\n",
       " 'AMPCA': 89,\n",
       " 'CELNOS': 90,\n",
       " 'OPHSC': 91,\n",
       " 'HCC': 92,\n",
       " 'STSC': 93,\n",
       " 'DSTAD': 94,\n",
       " 'EHCH': 95,\n",
       " 'GSARC': 96,\n",
       " 'BTMOV': 97,\n",
       " 'READ': 98,\n",
       " 'UCS': 99,\n",
       " 'CCOV': 100,\n",
       " 'BPLL': 101,\n",
       " 'PANET': 102,\n",
       " 'DCIS': 103,\n",
       " 'STAS': 104,\n",
       " 'LUAS': 105,\n",
       " 'UCCC': 106,\n",
       " 'SKCM': 107,\n",
       " 'CLLSLL': 108,\n",
       " 'HPHSC': 109,\n",
       " 'GCLC': 110,\n",
       " 'USARC': 111,\n",
       " 'THPD': 112,\n",
       " 'MDS': 113,\n",
       " 'CESC': 114,\n",
       " 'LXSC': 115,\n",
       " 'SS': 116,\n",
       " 'DDCHS': 117,\n",
       " 'DA': 118,\n",
       " 'MBN': 119,\n",
       " 'MLADS': 120,\n",
       " 'LIHB': 121,\n",
       " 'MXOV': 122,\n",
       " 'SSRCC': 123,\n",
       " 'MSTAD': 124,\n",
       " 'LUCA': 125,\n",
       " 'MFH': 126,\n",
       " 'BLSC': 127,\n",
       " 'AASTR': 128,\n",
       " 'ESS': 129,\n",
       " 'PEL': 130,\n",
       " 'ULMS': 131,\n",
       " 'UASC': 132,\n",
       " 'UCU': 133,\n",
       " 'MACR': 134,\n",
       " 'LUMEC': 135,\n",
       " 'ECAD': 136,\n",
       " 'THME': 137}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_2_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dcell_vae(nn.Module):\n",
    "\n",
    "    def __init__(self, term_size_map, term_direct_gene_map, dG, ngene, root, \n",
    "                 num_hiddens_genotype, num_hiddens_final, n_class, inter_loss_penalty = 0.2):\n",
    "\n",
    "        super(dcell_vae, self).__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.num_hiddens_genotype = num_hiddens_genotype\n",
    "        self.num_hiddens_final = num_hiddens_final\n",
    "        self.n_class = n_class\n",
    "        self.inter_loss_penalty = inter_loss_penalty\n",
    "        self.dG = copy.deepcopy(dG)\n",
    "\n",
    "        # dictionary from terms to genes directly annotated with the term\n",
    "        self.term_direct_gene_map = term_direct_gene_map\n",
    "\n",
    "        self.term_visit_count = {}\n",
    "        self.init_term_visits(term_size_map)\n",
    "        \n",
    "        # calculate the number of values in a state (term): term_size_map is the number of all genes annotated with the term\n",
    "        self.term_dim_map = {}\n",
    "        self.cal_term_dim(term_size_map)\n",
    "\n",
    "        # ngenes, gene_dim are the number of all genes\n",
    "        self.gene_dim = ngene\n",
    "\n",
    "        # add modules for neural networks to process genotypes\n",
    "        self.contruct_direct_gene_layer()\n",
    "        self.construct_NN_graph(self.dG)\n",
    "\n",
    "        # add modules for final layer TODO: modify it into VAE\n",
    "        final_input_size = num_hiddens_genotype # + num_hiddens_drug[-1]\n",
    "        self.add_module('final_linear_layer', nn.Linear(final_input_size, num_hiddens_final * 2))\n",
    "        self.add_module('final_batchnorm_layer', nn.BatchNorm1d(num_hiddens_final * 2))\n",
    "        self.add_module('final_aux_linear_layer', nn.Linear(num_hiddens_final * 2, 1))\n",
    "        self.add_module('final_linear_layer_output', nn.Linear(1, 1))\n",
    "        \n",
    "        self.decoder_affine = nn.Linear(num_hiddens_final, n_class)\n",
    "\n",
    "    def init_term_visits(self, term_size_map):\n",
    "        \n",
    "        for term in term_size_map:\n",
    "            self.term_visit_count[term] = 0\n",
    "    \n",
    "    # calculate the number of values in a state (term)\n",
    "    def cal_term_dim(self, term_size_map):\n",
    "\n",
    "        for term, term_size in term_size_map.items():\n",
    "            num_output = self.num_hiddens_genotype\n",
    "\n",
    "            # log the number of hidden variables per each term\n",
    "            num_output = int(num_output)\n",
    "#            print(\"term\\t%s\\tterm_size\\t%d\\tnum_hiddens\\t%d\" % (term, term_size, num_output))\n",
    "            self.term_dim_map[term] = num_output\n",
    "\n",
    "\n",
    "    # build a layer for forwarding gene that are directly annotated with the term\n",
    "    def contruct_direct_gene_layer(self):\n",
    "\n",
    "        for term, gene_set in self.term_direct_gene_map.items():\n",
    "            if len(gene_set) == 0:\n",
    "                print('There are no directed asscoiated genes for', term)\n",
    "                sys.exit(1)\n",
    "\n",
    "            # if there are some genes directly annotated with the term, add a layer taking in all genes and forwarding out only those genes\n",
    "            self.add_module(term+'_direct_gene_layer', nn.Linear(self.gene_dim, len(gene_set)))\n",
    "\n",
    "    # start from bottom (leaves), and start building a neural network using the given ontology\n",
    "    # adding modules --- the modules are not connected yet\n",
    "    def construct_NN_graph(self, dG):\n",
    "\n",
    "        self.term_layer_list = []   # term_layer_list stores the built neural network\n",
    "        self.term_neighbor_map = {}\n",
    "\n",
    "        # term_neighbor_map records all children of each term\n",
    "        for term in dG.nodes():\n",
    "            self.term_neighbor_map[term] = []\n",
    "            for child in dG.neighbors(term):\n",
    "                self.term_neighbor_map[term].append(child)\n",
    "\n",
    "        while True:\n",
    "            leaves = [n for n in dG.nodes() if dG.out_degree(n) == 0]\n",
    "            #leaves = [n for n,d in dG.out_degree().items() if d==0]\n",
    "            #leaves = [n for n,d in dG.out_degree() if d==0]\n",
    "\n",
    "            if len(leaves) == 0:\n",
    "                break\n",
    "\n",
    "            self.term_layer_list.append(leaves)\n",
    "\n",
    "            for term in leaves:\n",
    "\n",
    "                # input size will be #chilren + #genes directly annotated by the term\n",
    "                input_size = 0\n",
    "\n",
    "                for child in self.term_neighbor_map[term]:\n",
    "                    input_size += self.term_dim_map[child]\n",
    "\n",
    "                if term in self.term_direct_gene_map:\n",
    "                    input_size += len(self.term_direct_gene_map[term])\n",
    "\n",
    "                # term_hidden is the number of the hidden variables in each state\n",
    "                term_hidden = self.term_dim_map[term]\n",
    "\n",
    "                self.add_module(term+'_linear_layer', nn.Linear(input_size, term_hidden))\n",
    "                self.add_module(term+'_batchnorm_layer', nn.BatchNorm1d(term_hidden))\n",
    "                self.add_module(term+'_aux_linear_layer1', nn.Linear(term_hidden, self.n_class))\n",
    "                self.add_module(term+'_aux_linear_layer2', nn.Linear(self.n_class, self.n_class))\n",
    "\n",
    "            dG.remove_nodes_from(leaves)\n",
    "\n",
    "\n",
    "    # definition of encoder\n",
    "    def encoder(self, x):\n",
    "        gene_input = x.narrow(1, 0, self.gene_dim)\n",
    "\n",
    "        # define forward function for genotype dcell #############################################\n",
    "        term_gene_out_map = {}\n",
    "\n",
    "        for term, _ in self.term_direct_gene_map.items():\n",
    "            term_gene_out_map[term] = self._modules[term + '_direct_gene_layer'](gene_input)\n",
    "\n",
    "        term_NN_out_map = {}\n",
    "        aux_out_map = {}\n",
    "\n",
    "        for i, layer in enumerate(self.term_layer_list):\n",
    "\n",
    "            for term in layer:\n",
    "\n",
    "                child_input_list = []\n",
    "\n",
    "                self.term_visit_count[term] += 1\n",
    "                \n",
    "                for child in self.term_neighbor_map[term]:\n",
    "                    child_input_list.append(term_NN_out_map[child])\n",
    "\n",
    "                if term in self.term_direct_gene_map:\n",
    "                    child_input_list.append(term_gene_out_map[term])\n",
    "\n",
    "                child_input = torch.cat(child_input_list,1)\n",
    "\n",
    "                term_NN_out = self._modules[term+'_linear_layer'](child_input)\n",
    "\n",
    "                Tanh_out = torch.tanh(term_NN_out)\n",
    "                term_NN_out_map[term] = self._modules[term+'_batchnorm_layer'](Tanh_out)\n",
    "                aux_layer1_out = torch.tanh(self._modules[term+'_aux_linear_layer1'](term_NN_out_map[term]))\n",
    "                aux_out_map[term] = self._modules[term+'_aux_linear_layer2'](aux_layer1_out)\n",
    "\n",
    "        # connect two neural networks at the top #################################################\n",
    "        final_input = term_NN_out_map[self.root] # torch.cat((term_NN_out_map[self.root], drug_out), 1)\n",
    "\n",
    "        out = self._modules['final_batchnorm_layer'](torch.tanh(self._modules['final_linear_layer'](final_input)))\n",
    "        term_NN_out_map['final'] = out\n",
    "\n",
    "        aux_layer_out = torch.tanh(self._modules['final_aux_linear_layer'](out))\n",
    "        aux_out_map['final'] = self._modules['final_linear_layer_output'](aux_layer_out)\n",
    "\n",
    "        return aux_out_map, term_NN_out_map\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        aux_out_map, term_NN_out_map = self.encoder(x)\n",
    "        \n",
    "        mu = term_NN_out_map['final'][..., :self.num_hiddens_final]\n",
    "        log_var = term_NN_out_map['final'][..., :self.num_hiddens_final]  # T X batch X z_dim\n",
    "        std_dec = log_var.mul(0.5).exp_()\n",
    "        # std_dec = 1\n",
    "        \n",
    "        latent = MultivariateNormal(loc = mu, \n",
    "                                    scale_tril=torch.diag_embed(std_dec))\n",
    "        z = latent.rsample()\n",
    "        \n",
    "        recon_mean = self.decoder_affine(z)\n",
    "        logits = F.softmax(recon_mean, -1)\n",
    "\n",
    "        return logits, mu, log_var, aux_out_map, term_NN_out_map\n",
    "    \n",
    "    def loss_log_vae(self, logits, y, mu, log_var, beta = 0.001):\n",
    "        # y: true labels\n",
    "        ori_y_shape = y.shape\n",
    "        \n",
    "        class_loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), \n",
    "                                     y.reshape(-1), reduction = 'none').div(np.log(2)).view(*ori_y_shape)\n",
    "        \n",
    "        KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), \n",
    "                              dim = -1)\n",
    "        \n",
    "        log_loss = class_loss + beta * KLD\n",
    "        log_loss = torch.mean(torch.logsumexp(log_loss, 0))\n",
    "        \n",
    "        return log_loss\n",
    "    \n",
    "    def intermediate_loss(self, aux_out_map, y):\n",
    "        \n",
    "        inter_loss = 0\n",
    "        for name, output in aux_out_map.items():\n",
    "            if name == 'final':\n",
    "                inter_loss += 0\n",
    "            else: # change 0.2 to smaller one for big terms\n",
    "                ori_y_shape = y.shape\n",
    "        \n",
    "                term_loss = F.cross_entropy(output.view(-1, logits.shape[-1]), \n",
    "                                             y.reshape(-1), \n",
    "                                             reduction = 'none').div(np.log(2)).view(*ori_y_shape)\n",
    "                inter_loss += term_loss\n",
    "\n",
    "        return inter_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNASeqData(Dataset):\n",
    "    \n",
    "    def __init__(self, X, c=None, y=None, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.c = c\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.X[index,:]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        if self.y is not None and self.c is None:\n",
    "            return sample, self.y[index]\n",
    "        elif self.y is not None and self.c is not None:\n",
    "            return sample, self.y[index], self.c[index]\n",
    "        elif self.y is None and self.c is not None:\n",
    "            return sample, self.c[index]\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(cancer_type_idx)\n",
    "gdsc_dataset = RNASeqData(X = gdsc_tensor, y = y)\n",
    "training_set, testing_set = random_split(gdsc_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 200\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_set, batch_size=len(testing_set), shuffle=False)\n",
    "(inputdata, labels) = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3008])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_mask(term_direct_gene_map, gene_dim, device):\n",
    "\n",
    "    term_mask_map = {}\n",
    "\n",
    "    for term, gene_set in term_direct_gene_map.items():\n",
    "\n",
    "        mask = torch.zeros(len(gene_set), gene_dim)\n",
    "\n",
    "        for i, gene_id in enumerate(gene_set):\n",
    "            mask[i, gene_id] = 1\n",
    "\n",
    "        mask_gpu = torch.autograd.Variable(mask)\n",
    "\n",
    "        term_mask_map[term] = mask_gpu.to(device)\n",
    "\n",
    "    return term_mask_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [17:05<1:20:16, 58.04s/it, Epoch=16, Loss=2.36e+3, Accuracy=0.0498]"
     ]
    }
   ],
   "source": [
    "num_hiddens_genotype = 6\n",
    "num_hiddens_final = 6\n",
    "\n",
    "model = dcell_vae(term_size_map, term_direct_gene_map, dG, num_genes, \n",
    "                 root, num_hiddens_genotype, num_hiddens_final, n_class = len(cancer_2_idx))\n",
    "model.to(DEVICE)\n",
    "term_mask_map = create_term_mask(model.term_direct_gene_map, num_genes, device = DEVICE)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(0)\n",
    "loss_list = []\n",
    "accu_list = []\n",
    "train_epochs = 100\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99), eps=1e-05)\n",
    "term_mask_map = create_term_mask(model.term_direct_gene_map, gene_dim=num_genes, device=DEVICE)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    term_name = name.split('_')[0]\n",
    "\n",
    "    if '_direct_gene_layer.weight' in name:\n",
    "        param.data = torch.mul(param.data, term_mask_map[term_name].to(DEVICE)) * 0.1\n",
    "    else:\n",
    "        param.data = param.data * 0.1\n",
    "\n",
    "tepoch = tqdm.tqdm(range(train_epochs))\n",
    "for epoch in tepoch:\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_predict = torch.zeros(0, 0).to(DEVICE)\n",
    "\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Convert torch tensor to Variable\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "\n",
    "        # Here term_NN_out_map is a dictionary\n",
    "        logits, mu, log_var, aux_out_map, term_NN_out_map = model(data.to(DEVICE))\n",
    "\n",
    "        if train_predict.size()[0] == 0:\n",
    "            train_predict = aux_out_map[\"final\"].data\n",
    "        else:\n",
    "            train_predict = torch.cat([train_predict, aux_out_map[\"final\"].data], dim=0)\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        loss_vae = model.loss_log_vae(\n",
    "            logits=logits, y=labels.to(DEVICE), mu=mu, log_var=log_var, beta=0.001\n",
    "        )\n",
    "\n",
    "        loss_intermidiate = model.intermediate_loss(aux_out_map, labels.to(DEVICE))\n",
    "\n",
    "        total_loss = torch.mean(loss_vae + model.inter_loss_penalty * loss_intermidiate)\n",
    "        \n",
    "        tmp_loss = total_loss.item()\n",
    "        \n",
    "        total_loss.backward()\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"_direct_gene_layer.weight\" not in name:\n",
    "                continue\n",
    "            term_name = name.split(\"_\")[0]\n",
    "            # print name, param.grad.data.size(), term_mask_map[term_name].size()\n",
    "            param.grad.data = torch.mul(param.grad.data, term_mask_map[term_name])\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    (inputdata, labels) = next(iter(test_loader))\n",
    "    logits, mu, log_var, aux_out_map, term_NN_out_map = model(inputdata.to(DEVICE))\n",
    "\n",
    "    accu = torch.sum(torch.argmax(logits, 1).cpu() == labels)/len(labels)\n",
    "    \n",
    "    tepoch.set_postfix({\"Epoch\": epoch, \"Loss\": tmp_loss, \"Accuracy\": accu.item()})\n",
    "    \n",
    "    loss_list.append(tmp_loss)\n",
    "    accu_list.append(accu.item())\n",
    "    # if epoch % 10 == 0:\n",
    "    torch.save(model, \"gdsc_50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"gdsc_50.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_top5 = copy.deepcopy(cancer_type_idx)\n",
    "\n",
    "for idx, y_tmp in enumerate(cancer_type_idx):\n",
    "    if y_tmp in [2,13,24,30,14]:\n",
    "        y_top5[idx] = 1\n",
    "    else:\n",
    "        y_top5[idx] = 0\n",
    "    \n",
    "y_top5_train = y_top5[:700]\n",
    "y_top5_test = y_top5[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(cancer_type_idx)\n",
    "gdsc_dataset = RNASeqData(X = gdsc_tensor, y = torch.tensor(y_top5))\n",
    "training_set, testing_set = random_split(gdsc_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 256\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_set, batch_size=len(testing_set), shuffle=False)\n",
    "(inputdata, labels) = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_mask(term_direct_gene_map, gene_dim, device):\n",
    "\n",
    "    term_mask_map = {}\n",
    "\n",
    "    for term, gene_set in term_direct_gene_map.items():\n",
    "\n",
    "        mask = torch.zeros(len(gene_set), gene_dim)\n",
    "\n",
    "        for i, gene_id in enumerate(gene_set):\n",
    "            mask[i, gene_id] = 1\n",
    "\n",
    "        mask_gpu = torch.autograd.Variable(mask)\n",
    "\n",
    "        term_mask_map[term] = mask_gpu.to(device)\n",
    "\n",
    "    return term_mask_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens_genotype = 6\n",
    "num_hiddens_final = 6\n",
    "\n",
    "model = dcell_vae(term_size_map, term_direct_gene_map, dG, num_genes, \n",
    "                 root, num_hiddens_genotype, num_hiddens_final, n_class = 2)\n",
    "model.to(DEVICE)\n",
    "term_mask_map = create_term_mask(model.term_direct_gene_map, num_genes, device = DEVICE)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(0)\n",
    "loss_list = []\n",
    "accu_list = []\n",
    "train_epochs = 100\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99), eps=1e-05)\n",
    "term_mask_map = create_term_mask(model.term_direct_gene_map, gene_dim=num_genes, device=DEVICE)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    term_name = name.split('_')[0]\n",
    "\n",
    "    if '_direct_gene_layer.weight' in name:\n",
    "        param.data = torch.mul(param.data, term_mask_map[term_name].to(DEVICE)) * 0.1\n",
    "    else:\n",
    "        param.data = param.data * 0.1\n",
    "\n",
    "tepoch = tqdm.tqdm(range(train_epochs))\n",
    "for epoch in tepoch:\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_predict = torch.zeros(0, 0).to(DEVICE)\n",
    "\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Convert torch tensor to Variable\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "\n",
    "        # Here term_NN_out_map is a dictionary\n",
    "        logits, mu, log_var, aux_out_map, term_NN_out_map = model(data.to(DEVICE))\n",
    "\n",
    "        if train_predict.size()[0] == 0:\n",
    "            train_predict = aux_out_map[\"final\"].data\n",
    "        else:\n",
    "            train_predict = torch.cat([train_predict, aux_out_map[\"final\"].data], dim=0)\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        loss_vae = model.loss_log_vae(\n",
    "            logits=logits, y=labels.to(DEVICE), mu=mu, log_var=log_var, beta=0.001\n",
    "        )\n",
    "\n",
    "        loss_intermidiate = model.intermediate_loss(aux_out_map, labels.to(DEVICE))\n",
    "\n",
    "        total_loss = torch.mean(loss_vae + model.inter_loss_penalty * loss_intermidiate)\n",
    "        \n",
    "        tmp_loss = total_loss.item()\n",
    "        \n",
    "        total_loss.backward()\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"_direct_gene_layer.weight\" not in name:\n",
    "                continue\n",
    "            term_name = name.split(\"_\")[0]\n",
    "            # print name, param.grad.data.size(), term_mask_map[term_name].size()\n",
    "            param.grad.data = torch.mul(param.grad.data, term_mask_map[term_name])\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    (inputdata, labels) = next(iter(test_loader))\n",
    "    logits, mu, log_var, aux_out_map, term_NN_out_map = model(inputdata.to(DEVICE))\n",
    "\n",
    "    accu = torch.sum(torch.argmax(logits, 1).cpu() == labels)/len(labels)\n",
    "    \n",
    "    tepoch.set_postfix({\"Epoch\": epoch, \"Loss\": tmp_loss, \"Accuracy\": accu.item()})\n",
    "    \n",
    "    loss_list.append(tmp_loss)\n",
    "    accu_list.append(accu.item())\n",
    "    # if epoch % 10 == 0:\n",
    "    torch.save(model, \"gdsc_50_top5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"gdsc_50_top5.pt\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inputdata, labels) = next(iter(test_loader))\n",
    "logits, mu, log_var, aux_out_map, term_NN_out_map = model(inputdata.to(DEVICE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343447905477981"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels, logits[:,1].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9552)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.argmax(logits, 1).cpu() == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding drug embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drugcell_Vae(nn.Module):\n",
    "\n",
    "    def __init__(self, term_size_map, term_direct_gene_map, dG, ngene, ndrug, root, \n",
    "                 num_hiddens_genotype, num_hiddens_drug, num_hiddens_final, \n",
    "                 n_class, inter_loss_penalty = 0.2):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.num_hiddens_genotype = num_hiddens_genotype\n",
    "        self.num_hiddens_drug = num_hiddens_drug\n",
    "        \n",
    "        \n",
    "        self.num_hiddens_final = num_hiddens_final\n",
    "        self.n_class = n_class\n",
    "        self.inter_loss_penalty = inter_loss_penalty\n",
    "        self.dG = copy.deepcopy(dG)\n",
    "\n",
    "        # dictionary from terms to genes directly annotated with the term\n",
    "        self.term_direct_gene_map = term_direct_gene_map\n",
    "\n",
    "        self.term_visit_count = {}\n",
    "        self.init_term_visits(term_size_map)\n",
    "        \n",
    "        # calculate the number of values in a state (term): term_size_map is the number of all genes annotated with the term\n",
    "        self.term_dim_map = {}\n",
    "        self.cal_term_dim(term_size_map)\n",
    "\n",
    "        # ngenes, gene_dim are the number of all genes\n",
    "        self.gene_dim = ngene\n",
    "        self.drug_dim = ndrug\n",
    "\n",
    "        # add modules for neural networks to process genotypes\n",
    "        self.contruct_direct_gene_layer()\n",
    "        self.construct_NN_graph(self.dG)\n",
    "\n",
    "        # add modules for neural networks to process drugs\n",
    "        self.construct_NN_drug()\n",
    "\n",
    "        # add modules for final layer TODO: modify it into VAE\n",
    "        final_input_size = num_hiddens_genotype + num_hiddens_drug[-1]\n",
    "        self.add_module('final_linear_layer', nn.Linear(final_input_size, num_hiddens_final * 2))\n",
    "        self.add_module('final_batchnorm_layer', nn.BatchNorm1d(num_hiddens_final * 2))\n",
    "        self.add_module('final_aux_linear_layer', nn.Linear(num_hiddens_final * 2, 1))\n",
    "        self.add_module('final_linear_layer_output', nn.Linear(1, 1))\n",
    "        \n",
    "        self.decoder_affine = nn.Linear(num_hiddens_final, n_class)\n",
    "\n",
    "    def init_term_visits(self, term_size_map):\n",
    "        \n",
    "        for term in term_size_map:\n",
    "            self.term_visit_count[term] = 0\n",
    "    \n",
    "    # calculate the number of values in a state (term)\n",
    "    def cal_term_dim(self, term_size_map):\n",
    "\n",
    "        for term, term_size in term_size_map.items():\n",
    "            num_output = self.num_hiddens_genotype\n",
    "\n",
    "            # log the number of hidden variables per each term\n",
    "            num_output = int(num_output)\n",
    "#            print(\"term\\t%s\\tterm_size\\t%d\\tnum_hiddens\\t%d\" % (term, term_size, num_output))\n",
    "            self.term_dim_map[term] = num_output\n",
    "\n",
    "\n",
    "    # build a layer for forwarding gene that are directly annotated with the term\n",
    "    def contruct_direct_gene_layer(self):\n",
    "\n",
    "        for term, gene_set in self.term_direct_gene_map.items():\n",
    "            if len(gene_set) == 0:\n",
    "                print('There are no directed asscoiated genes for', term)\n",
    "                sys.exit(1)\n",
    "\n",
    "            # if there are some genes directly annotated with the term, add a layer taking in all genes and forwarding out only those genes\n",
    "            self.add_module(term+'_direct_gene_layer', nn.Linear(self.gene_dim, len(gene_set)))\n",
    "\n",
    "\n",
    "    # add modules for fully connected neural networks for drug processing\n",
    "    def construct_NN_drug(self):\n",
    "        input_size = self.drug_dim\n",
    "\n",
    "        for i in range(len(self.num_hiddens_drug)):\n",
    "            self.add_module('drug_linear_layer_' + str(i+1), nn.Linear(input_size, self.num_hiddens_drug[i]))\n",
    "            self.add_module('drug_batchnorm_layer_' + str(i+1), nn.BatchNorm1d(self.num_hiddens_drug[i]))\n",
    "            self.add_module('drug_aux_linear_layer1_' + str(i+1), nn.Linear(self.num_hiddens_drug[i],1))\n",
    "            self.add_module('drug_aux_linear_layer2_' + str(i+1), nn.Linear(1,1))\n",
    "\n",
    "            input_size = self.num_hiddens_drug[i]\n",
    "\n",
    "    # start from bottom (leaves), and start building a neural network using the given ontology\n",
    "    # adding modules --- the modules are not connected yet\n",
    "    def construct_NN_graph(self, dG):\n",
    "\n",
    "        self.term_layer_list = []   # term_layer_list stores the built neural network\n",
    "        self.term_neighbor_map = {}\n",
    "\n",
    "        # term_neighbor_map records all children of each term\n",
    "        for term in dG.nodes():\n",
    "            self.term_neighbor_map[term] = []\n",
    "            for child in dG.neighbors(term):\n",
    "                self.term_neighbor_map[term].append(child)\n",
    "\n",
    "        while True:\n",
    "            leaves = [n for n in dG.nodes() if dG.out_degree(n) == 0]\n",
    "            #leaves = [n for n,d in dG.out_degree().items() if d==0]\n",
    "            #leaves = [n for n,d in dG.out_degree() if d==0]\n",
    "\n",
    "            if len(leaves) == 0:\n",
    "                break\n",
    "\n",
    "            self.term_layer_list.append(leaves)\n",
    "\n",
    "            for term in leaves:\n",
    "\n",
    "                # input size will be #chilren + #genes directly annotated by the term\n",
    "                input_size = 0\n",
    "\n",
    "                for child in self.term_neighbor_map[term]:\n",
    "                    input_size += self.term_dim_map[child]\n",
    "\n",
    "                if term in self.term_direct_gene_map:\n",
    "                    input_size += len(self.term_direct_gene_map[term])\n",
    "\n",
    "                # term_hidden is the number of the hidden variables in each state\n",
    "                term_hidden = self.term_dim_map[term]\n",
    "\n",
    "                self.add_module(term+'_linear_layer', nn.Linear(input_size, term_hidden))\n",
    "                self.add_module(term+'_batchnorm_layer', nn.BatchNorm1d(term_hidden))\n",
    "                self.add_module(term+'_aux_linear_layer1', nn.Linear(term_hidden, self.n_class))\n",
    "                self.add_module(term+'_aux_linear_layer2', nn.Linear(self.n_class, self.n_class))\n",
    "\n",
    "            dG.remove_nodes_from(leaves)\n",
    "\n",
    "\n",
    "    # definition of encoder\n",
    "    def encoder(self, x):\n",
    "        gene_input = x.narrow(1, 0, self.gene_dim)\n",
    "\n",
    "        # define forward function for genotype dcell #############################################\n",
    "        term_gene_out_map = {}\n",
    "\n",
    "        for term, _ in self.term_direct_gene_map.items():\n",
    "            term_gene_out_map[term] = self._modules[term + '_direct_gene_layer'](gene_input)\n",
    "\n",
    "        term_NN_out_map = {}\n",
    "        aux_out_map = {}\n",
    "\n",
    "        for i, layer in enumerate(self.term_layer_list):\n",
    "\n",
    "            for term in layer:\n",
    "\n",
    "                child_input_list = []\n",
    "\n",
    "                self.term_visit_count[term] += 1\n",
    "                \n",
    "                for child in self.term_neighbor_map[term]:\n",
    "                    child_input_list.append(term_NN_out_map[child])\n",
    "\n",
    "                if term in self.term_direct_gene_map:\n",
    "                    child_input_list.append(term_gene_out_map[term])\n",
    "\n",
    "                child_input = torch.cat(child_input_list,1)\n",
    "\n",
    "                term_NN_out = self._modules[term+'_linear_layer'](child_input)\n",
    "\n",
    "                Tanh_out = torch.tanh(term_NN_out)\n",
    "                term_NN_out_map[term] = self._modules[term+'_batchnorm_layer'](Tanh_out)\n",
    "                aux_layer1_out = torch.tanh(self._modules[term+'_aux_linear_layer1'](term_NN_out_map[term]))\n",
    "                aux_out_map[term] = self._modules[term+'_aux_linear_layer2'](aux_layer1_out)\n",
    "\n",
    "        # connect two neural networks at the top #################################################\n",
    "        final_input = term_NN_out_map[self.root] # torch.cat((term_NN_out_map[self.root], drug_out), 1)\n",
    "\n",
    "        out = self._modules['final_batchnorm_layer'](torch.tanh(self._modules['final_linear_layer'](final_input)))\n",
    "        term_NN_out_map['final'] = out\n",
    "\n",
    "        aux_layer_out = torch.tanh(self._modules['final_aux_linear_layer'](out))\n",
    "        aux_out_map['final'] = self._modules['final_linear_layer_output'](aux_layer_out)\n",
    "\n",
    "        return aux_out_map, term_NN_out_map\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        gene_input = x.narrow(1, 0, self.gene_dim)\n",
    "        drug_input = x.narrow(1, self.gene_dim, self.drug_dim)\n",
    "        \n",
    "        aux_out_map, term_NN_out_map = self.encoder(gene_input)\n",
    "        \n",
    "        mu = term_NN_out_map['final'][..., :self.num_hiddens_final]\n",
    "        log_var = term_NN_out_map['final'][..., :self.num_hiddens_final]  # T X batch X z_dim\n",
    "        std_dec = log_var.mul(0.5).exp_()\n",
    "        # std_dec = 1\n",
    "        \n",
    "        latent = MultivariateNormal(loc = mu, \n",
    "                                    scale_tril=torch.diag_embed(std_dec))\n",
    "        z = latent.rsample()\n",
    "        \n",
    "        # define forward function for drug dcell #################################################\n",
    "        drug_out = drug_input\n",
    "\n",
    "        for i in range(1, len(self.num_hiddens_drug)+1, 1):\n",
    "            drug_out = self._modules['drug_batchnorm_layer_'+str(i)]( torch.tanh(self._modules['drug_linear_layer_' + str(i)](drug_out)))\n",
    "            term_NN_out_map['drug_'+str(i)] = drug_out\n",
    "\n",
    "            aux_layer1_out = torch.tanh(self._modules['drug_aux_linear_layer1_'+str(i)](drug_out))\n",
    "            aux_out_map['drug_'+str(i)] = self._modules['drug_aux_linear_layer2_'+str(i)](aux_layer1_out)\n",
    "\n",
    "        final_input = torch.cat((z, drug_out), 1)  # Check this part\n",
    "        \n",
    "        recon_mean = self.decoder_affine(final_input)\n",
    "        logits = F.softmax(recon_mean, -1)\n",
    "\n",
    "        return logits, mu, log_var, aux_out_map, term_NN_out_map\n",
    "    \n",
    "    def loss_log_vae(self, logits, y, mu, log_var, beta = 0.001):\n",
    "        # y: true labels\n",
    "        ori_y_shape = y.shape\n",
    "        \n",
    "        class_loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), \n",
    "                                     y.reshape(-1), reduction = 'none').div(np.log(2)).view(*ori_y_shape)\n",
    "        \n",
    "        KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), \n",
    "                              dim = -1)\n",
    "        \n",
    "        log_loss = class_loss + beta * KLD\n",
    "        log_loss = torch.mean(torch.logsumexp(log_loss, 0))\n",
    "        \n",
    "        return log_loss\n",
    "    \n",
    "    def intermediate_loss(self, aux_out_map, y):\n",
    "        \n",
    "        inter_loss = 0\n",
    "        for name, output in aux_out_map.items():\n",
    "            if name == 'final':\n",
    "                inter_loss += 0\n",
    "            else: # change 0.2 to smaller one for big terms\n",
    "                ori_y_shape = y.shape\n",
    "        \n",
    "                term_loss = F.cross_entropy(output.view(-1, logits.shape[-1]), \n",
    "                                             y.reshape(-1), \n",
    "                                             reduction = 'none').div(np.log(2)).view(*ori_y_shape)\n",
    "                inter_loss += term_loss\n",
    "\n",
    "        return inter_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label, test_feature, test_label = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = du.DataLoader(du.TensorDataset(train_feature,train_label),\n",
    "                                 batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_features = np.genfromtxt(genotype_file, delimiter=',')\n",
    "drug_features = np.genfromtxt(fingerprint_file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecfp4.0</th>\n",
       "      <th>ecfp4.1</th>\n",
       "      <th>ecfp4.2</th>\n",
       "      <th>ecfp4.3</th>\n",
       "      <th>ecfp4.4</th>\n",
       "      <th>ecfp4.5</th>\n",
       "      <th>ecfp4.6</th>\n",
       "      <th>ecfp4.7</th>\n",
       "      <th>ecfp4.8</th>\n",
       "      <th>ecfp4.9</th>\n",
       "      <th>...</th>\n",
       "      <th>ecfp4.502</th>\n",
       "      <th>ecfp4.503</th>\n",
       "      <th>ecfp4.504</th>\n",
       "      <th>ecfp4.505</th>\n",
       "      <th>ecfp4.506</th>\n",
       "      <th>ecfp4.507</th>\n",
       "      <th>ecfp4.508</th>\n",
       "      <th>ecfp4.509</th>\n",
       "      <th>ecfp4.510</th>\n",
       "      <th>ecfp4.511</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improve_chem_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drug_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_1000</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1565 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ecfp4.0  ecfp4.1  ecfp4.2  ecfp4.3  ecfp4.4  ecfp4.5  \\\n",
       "improve_chem_id                                                         \n",
       "Drug_0                 0        0        0        0        0        0   \n",
       "Drug_1                 0        0        0        0        0        0   \n",
       "Drug_10                0        0        0        0        0        0   \n",
       "Drug_100               0        0        0        0        0        0   \n",
       "Drug_1000              0        1        0        0        0        0   \n",
       "...                  ...      ...      ...      ...      ...      ...   \n",
       "Drug_995               0        1        0        0        0        0   \n",
       "Drug_996               0        1        0        0        0        0   \n",
       "Drug_997               0        1        0        0        0        0   \n",
       "Drug_998               0        1        0        0        0        0   \n",
       "Drug_999               0        1        0        0        0        0   \n",
       "\n",
       "                 ecfp4.6  ecfp4.7  ecfp4.8  ecfp4.9  ...  ecfp4.502  \\\n",
       "improve_chem_id                                      ...              \n",
       "Drug_0                 0        0        0        0  ...          0   \n",
       "Drug_1                 0        0        0        0  ...          0   \n",
       "Drug_10                0        0        0        0  ...          0   \n",
       "Drug_100               0        0        0        0  ...          0   \n",
       "Drug_1000              0        0        0        0  ...          0   \n",
       "...                  ...      ...      ...      ...  ...        ...   \n",
       "Drug_995               0        0        0        0  ...          0   \n",
       "Drug_996               0        0        0        0  ...          0   \n",
       "Drug_997               0        0        0        0  ...          0   \n",
       "Drug_998               0        0        0        0  ...          0   \n",
       "Drug_999               0        0        0        0  ...          0   \n",
       "\n",
       "                 ecfp4.503  ecfp4.504  ecfp4.505  ecfp4.506  ecfp4.507  \\\n",
       "improve_chem_id                                                          \n",
       "Drug_0                   0          0          0          0          0   \n",
       "Drug_1                   0          0          0          0          0   \n",
       "Drug_10                  0          0          0          0          0   \n",
       "Drug_100                 0          1          0          0          0   \n",
       "Drug_1000                0          0          0          1          0   \n",
       "...                    ...        ...        ...        ...        ...   \n",
       "Drug_995                 0          0          0          0          1   \n",
       "Drug_996                 0          0          1          0          0   \n",
       "Drug_997                 1          0          0          0          0   \n",
       "Drug_998                 0          0          0          0          0   \n",
       "Drug_999                 0          0          0          0          0   \n",
       "\n",
       "                 ecfp4.508  ecfp4.509  ecfp4.510  ecfp4.511  \n",
       "improve_chem_id                                              \n",
       "Drug_0                   0          0          0          0  \n",
       "Drug_1                   0          0          0          0  \n",
       "Drug_10                  0          0          0          0  \n",
       "Drug_100                 0          0          0          0  \n",
       "Drug_1000                0          0          0          0  \n",
       "...                    ...        ...        ...        ...  \n",
       "Drug_995                 0          1          0          0  \n",
       "Drug_996                 0          0          0          0  \n",
       "Drug_997                 0          0          0          0  \n",
       "Drug_998                 0          0          0          0  \n",
       "Drug_999                 0          0          0          0  \n",
       "\n",
       "[1565 rows x 512 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_ecfp4_nbits512 = pd.read_csv(\"data/GDSC/drug_ecfp4_nbits512.tsv\", sep = '\\t', index_col=0)\n",
    "drug_ecfp4_nbits512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008\n",
      "2048\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "genedim = len(cell_features[0,:])\n",
    "drugdim = len(drug_features[0,:])\n",
    "print(genedim)\n",
    "print(drugdim)\n",
    "feature = np.zeros((inputdata.size()[0], (genedim+drugdim)))\n",
    "#print(input_data)\n",
    "print(inputdata.size()[0])\n",
    "#print(drug_features)\n",
    "\n",
    "for i in range(inputdata.size()[0]):\n",
    "    #print(int(input_data[i,0]))\n",
    "    try:\n",
    "        feature[i] = np.concatenate((cell_features[int(inputdata[i,0])], \n",
    "                                        drug_features[int(inputdata[i,1])]), axis=None)\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "feature = torch.from_numpy(feature).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "genedim = len(cell_features[0,:])\n",
    "drugdim = len(drug_features[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>improve_sample_id</th>\n",
       "      <th>improve_chem_id</th>\n",
       "      <th>study</th>\n",
       "      <th>auc</th>\n",
       "      <th>ic50</th>\n",
       "      <th>ec50</th>\n",
       "      <th>ec50se</th>\n",
       "      <th>r2fit</th>\n",
       "      <th>einf</th>\n",
       "      <th>hs</th>\n",
       "      <th>aac1</th>\n",
       "      <th>auc1</th>\n",
       "      <th>dss1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_749</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>5.6600</td>\n",
       "      <td>5.6600</td>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6669</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_1326</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0230</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_490</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>7.5460</td>\n",
       "      <td>7.5510</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>1.3380</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>0.6605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_558</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>5.1980</td>\n",
       "      <td>5.1980</td>\n",
       "      <td>11.7100</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.0291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>ACH-000956</td>\n",
       "      <td>Drug_895</td>\n",
       "      <td>fake_exp</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>7.0930</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>1.0150</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587704</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_470</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8900</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587705</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_343</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>3.0070</td>\n",
       "      <td>3.0070</td>\n",
       "      <td>46.7600</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587706</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_1190</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4040</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587707</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_89</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>233.0000</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587708</th>\n",
       "      <td>GDSCv2</td>\n",
       "      <td>ACH-000475</td>\n",
       "      <td>Drug_36</td>\n",
       "      <td>19498</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>4.7880</td>\n",
       "      <td>4.7880</td>\n",
       "      <td>2.8020</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587709 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source improve_sample_id improve_chem_id     study     auc    ic50  \\\n",
       "0         CCLE        ACH-000956        Drug_749  fake_exp  0.7153  5.6600   \n",
       "1         CCLE        ACH-000956       Drug_1326  fake_exp  0.9579     NaN   \n",
       "2         CCLE        ACH-000956        Drug_490  fake_exp  0.4130  7.5460   \n",
       "3         CCLE        ACH-000956        Drug_558  fake_exp  0.8004  5.1980   \n",
       "4         CCLE        ACH-000956        Drug_895  fake_exp  0.5071  7.0930   \n",
       "...        ...               ...             ...       ...     ...     ...   \n",
       "587704  GDSCv2        ACH-000475        Drug_470     19498  0.9548     NaN   \n",
       "587705  GDSCv2        ACH-000475        Drug_343     19498  0.8190  3.0070   \n",
       "587706  GDSCv2        ACH-000475       Drug_1190     19498  0.9105     NaN   \n",
       "587707  GDSCv2        ACH-000475         Drug_89     19498  0.9566  0.2428   \n",
       "587708  GDSCv2        ACH-000475         Drug_36     19498  0.8426  4.7880   \n",
       "\n",
       "          ec50    ec50se   r2fit    einf      hs    aac1    auc1    dss1  \n",
       "0       5.6600    0.6867  0.9533  0.0000  0.6669  0.2240  0.7760  0.1661  \n",
       "1       7.0230    0.7111  0.4332  0.9164  4.0000  0.0459  0.9541  0.0000  \n",
       "2       7.5510    0.0385  0.9948  0.0082  1.3380  0.6909  0.3091  0.6605  \n",
       "3       5.1980   11.7100  0.9944  0.0000  4.0000  0.0392  0.9608  0.0291  \n",
       "4       7.1490    0.3175  0.8069  0.0607  1.0150  0.5470  0.4530  0.5037  \n",
       "...        ...       ...     ...     ...     ...     ...     ...     ...  \n",
       "587704  7.8900    0.0000 -0.0000  0.9096  0.0000  0.0452  0.9548  0.0000  \n",
       "587705  3.0070   46.7600  0.4604  0.0000  0.1818  0.1943  0.8057  0.1047  \n",
       "587706  3.4040    0.0000 -0.0000  0.8209  0.0000  0.0895  0.9105  0.0000  \n",
       "587707  0.2428  233.0000  0.1946  0.0000  0.2200  0.0438  0.9562  0.0000  \n",
       "587708  4.7880    2.8020  0.8616  0.0000  0.6938  0.1111  0.8889  0.0573  \n",
       "\n",
       "[587709 rows x 14 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve_sample_key_id_dict = {k: v for v, k in enumerate(response['improve_sample_id'].unique())}\n",
    "improve_sample_id_key_dict = {v: k for v, k in enumerate(response['improve_sample_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_key_id_dict = {k: v for v, k in enumerate(response['improve_sample_id'].unique())}\n",
    "chem_id_key_dict = {v: k for v, k in enumerate(response['improve_sample_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_ecfp4_nbits512.loc[['Drug_749', 'Drug_36'],:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_list = list(set(gene2id_mapping.keys()) & set(gene_express.columns))\n",
    "gdsc_tensor = torch.zeros(gene_express.shape[0], num_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in gene_intersect_list:\n",
    "    idx = gene2id_mapping[gene]\n",
    "    gdsc_tensor[:,idx] = torch.tensor(gene_express[gene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_list = list(set(gene2id_mapping.keys()) & set(gdsc_x.columns))\n",
    "gdsc_tensor = torch.zeros(gene_express.shape[0], num_genes)\n",
    "gdsc_row_key_id = {k: v for v, k in enumerate(gene_express.index)}\n",
    "gdsc_row_id_key = {v: k for v, k in enumerate(gene_express.index)}\n",
    "\n",
    "chem_row_key_id = {k: v for v, k in enumerate(drug_ecfp4_nbits512.index)}\n",
    "chem_row_id_key = {v: k for v, k in enumerate(drug_ecfp4_nbits512.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_tensor = torch.tensor(drug_ecfp4_nbits512.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gdcs2 = response[response['source'] == 'GDSCv2'].loc[:,['improve_sample_id', \n",
    "                                                             'improve_chem_id',\n",
    "                                                             'auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gdcs2 = response_gdcs2.replace({'improve_sample_id': gdsc_row_key_id})\n",
    "response_gdcs2 = response_gdcs2.replace({'improve_chem_id': chem_row_key_id})\n",
    "response_gdcs2 = torch.tensor(response_gdcs2.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.4900e+02, 6.7400e+02, 5.8330e-01],\n",
       "        [9.4900e+02, 6.7400e+02, 6.0260e-01],\n",
       "        [9.4900e+02, 6.7400e+02, 4.3030e-01],\n",
       "        ...,\n",
       "        [5.1500e+02, 2.1400e+02, 9.1050e-01],\n",
       "        [5.1500e+02, 1.4430e+03, 9.5660e-01],\n",
       "        [5.1500e+02, 8.5500e+02, 8.4260e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_gdcs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDSCData(Dataset):\n",
    "    \n",
    "    def __init__(self, response, gene_tensor, chem_tensor):\n",
    "        self.response = response\n",
    "        self.gene_tensor = gene_tensor\n",
    "        self.chem_tensor = chem_tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.response.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.response[index,:]\n",
    "        \n",
    "        X_gene = self.gene_tensor[sample[:,0] ,:]\n",
    "        X_chem = self.gene_tensor[sample[:,1] ,:]\n",
    "        \n",
    "        y = self.gene_tensor[sample[:,2] ,:]\n",
    "\n",
    "        X = torch.cat((X_gene, X_chem), 1)\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [17:05<1:20:16, 58.04s/it, Epoch=16, Loss=2.36e+3, Accuracy=0.0498]"
     ]
    }
   ],
   "source": [
    "num_hiddens_genotype = 6\n",
    "num_hiddens_final = 6\n",
    "num_hiddens_drug = 6\n",
    "num_drugs = drug_ecfp4_nbits512.shape[1]\n",
    "\n",
    "model = Drugcell_Vae(term_size_map, term_direct_gene_map, dG, num_genes, num_drugs, \n",
    "                 root, num_hiddens_genotype, num_hiddens_drug, num_hiddens_final, \n",
    "                 n_class = len(cancer_2_idx))\n",
    "model.to(DEVICE)\n",
    "term_mask_map = create_term_mask(model.term_direct_gene_map, num_genes, device = DEVICE)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(0)\n",
    "loss_list = []\n",
    "accu_list = []\n",
    "train_epochs = 100\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99), eps=1e-05)\n",
    "term_mask_map = create_term_mask(model.term_direct_gene_map, gene_dim=num_genes, device=DEVICE)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    term_name = name.split('_')[0]\n",
    "\n",
    "    if '_direct_gene_layer.weight' in name:\n",
    "        param.data = torch.mul(param.data, term_mask_map[term_name].to(DEVICE)) * 0.1\n",
    "    else:\n",
    "        param.data = param.data * 0.1\n",
    "\n",
    "tepoch = tqdm.tqdm(range(train_epochs))\n",
    "for epoch in tepoch:\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_predict = torch.zeros(0, 0).to(DEVICE)\n",
    "\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Convert torch tensor to Variable\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "\n",
    "        # Here term_NN_out_map is a dictionary\n",
    "        logits, mu, log_var, aux_out_map, term_NN_out_map = model(data.to(DEVICE))\n",
    "\n",
    "        if train_predict.size()[0] == 0:\n",
    "            train_predict = aux_out_map[\"final\"].data\n",
    "        else:\n",
    "            train_predict = torch.cat([train_predict, aux_out_map[\"final\"].data], dim=0)\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        loss_vae = model.loss_log_vae(\n",
    "            logits=logits, y=labels.to(DEVICE), mu=mu, log_var=log_var, beta=0.001\n",
    "        )\n",
    "\n",
    "        loss_intermidiate = model.intermediate_loss(aux_out_map, labels.to(DEVICE))\n",
    "\n",
    "        total_loss = torch.mean(loss_vae + model.inter_loss_penalty * loss_intermidiate)\n",
    "        \n",
    "        tmp_loss = total_loss.item()\n",
    "        \n",
    "        total_loss.backward()\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"_direct_gene_layer.weight\" not in name:\n",
    "                continue\n",
    "            term_name = name.split(\"_\")[0]\n",
    "            # print name, param.grad.data.size(), term_mask_map[term_name].size()\n",
    "            param.grad.data = torch.mul(param.grad.data, term_mask_map[term_name])\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    (inputdata, labels) = next(iter(test_loader))\n",
    "    logits, mu, log_var, aux_out_map, term_NN_out_map = model(inputdata.to(DEVICE))\n",
    "\n",
    "    accu = torch.sum(torch.argmax(logits, 1).cpu() == labels)/len(labels)\n",
    "    \n",
    "    tepoch.set_postfix({\"Epoch\": epoch, \"Loss\": tmp_loss, \"Accuracy\": accu.item()})\n",
    "    \n",
    "    loss_list.append(tmp_loss)\n",
    "    accu_list.append(accu.item())\n",
    "    # if epoch % 10 == 0:\n",
    "    torch.save(model, \"gdsc_50.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
